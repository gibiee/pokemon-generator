{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gibiee/pokemon-generator/blob/main/2_train_in_colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DINc0Em3iCkG"
      },
      "source": [
        "<a target=\"_blank\" href=\"https://colab.research.google.com/github/gibiee/pokemon-generator/blob/main/2_train_in_colab.ipynb\">\n",
        "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
        "</a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6w4hQTYLiCkH",
        "outputId": "3165c6ce-10dc-4211-bf42-b132c2d8c95c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'pokemon-generator'...\n",
            "remote: Enumerating objects: 1247, done.\u001b[K\n",
            "remote: Counting objects: 100% (43/43), done.\u001b[K\n",
            "remote: Compressing objects: 100% (39/39), done.\u001b[K\n",
            "remote: Total 1247 (delta 15), reused 29 (delta 3), pack-reused 1204\u001b[K\n",
            "Receiving objects: 100% (1247/1247), 94.48 MiB | 13.94 MiB/s, done.\n",
            "Resolving deltas: 100% (17/17), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/gibiee/pokemon-generator.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_OVlt-MxiCkI",
        "outputId": "3d576ef8-d01d-4d0c-c637-a207a71aadb4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'stylegan2-ada-pytorch'...\n",
            "remote: Enumerating objects: 131, done.\u001b[K\n",
            "remote: Counting objects: 100% (3/3), done.\u001b[K\n",
            "remote: Compressing objects: 100% (3/3), done.\u001b[K\n",
            "remote: Total 131 (delta 0), reused 1 (delta 0), pack-reused 128\u001b[K\n",
            "Receiving objects: 100% (131/131), 1.13 MiB | 25.73 MiB/s, done.\n",
            "Resolving deltas: 100% (57/57), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/NVlabs/stylegan2-ada-pytorch.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J3kejbzJiCkI"
      },
      "outputs": [],
      "source": [
        "# pytorch 설치\n",
        "# !pip install click requests tqdm pyspng ninja imageio-ffmpeg==0.4.3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "uGqEMN__iCkI"
      },
      "outputs": [],
      "source": [
        "augpipe_specs = {\n",
        "    'blit':   dict(xflip=1, rotate90=1, xint=1),\n",
        "    'geom':   dict(scale=1, rotate=1, aniso=1, xfrac=1),\n",
        "    'color':  dict(brightness=1, contrast=1, lumaflip=1, hue=1, saturation=1),\n",
        "    'filter': dict(imgfilter=1),\n",
        "    'noise':  dict(noise=1),\n",
        "    'cutout': dict(cutout=1),\n",
        "    'bg':     dict(xflip=1, rotate90=1, xint=1, scale=1, rotate=1, aniso=1, xfrac=1),\n",
        "    'bgc':    dict(xflip=1, rotate90=1, xint=1, scale=1, rotate=1, aniso=1, xfrac=1, brightness=1, contrast=1, lumaflip=1, hue=1, saturation=1),\n",
        "    'bgcf':   dict(xflip=1, rotate90=1, xint=1, scale=1, rotate=1, aniso=1, xfrac=1, brightness=1, contrast=1, lumaflip=1, hue=1, saturation=1, imgfilter=1),\n",
        "    'bgcfn':  dict(xflip=1, rotate90=1, xint=1, scale=1, rotate=1, aniso=1, xfrac=1, brightness=1, contrast=1, lumaflip=1, hue=1, saturation=1, imgfilter=1, noise=1),\n",
        "    'bgcfnc': dict(xflip=1, rotate90=1, xint=1, scale=1, rotate=1, aniso=1, xfrac=1, brightness=1, contrast=1, lumaflip=1, hue=1, saturation=1, imgfilter=1, noise=1, cutout=1),\n",
        "}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "```py\n",
        "'custom': dict(xflip=1, rotate90=1, scale=1, rotate=1, aniso=1, xfrac=1, brightness=1, contrast=1, lumaflip=1, hue=1, saturation=1, imgfilter=1, noise=1, cutout=1)\n",
        "```"
      ],
      "metadata": {
        "id": "nV7lm5M6kwIQ"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rv6QBQBxiCkI"
      },
      "source": [
        "Line 271 in `stylegan2-ada-pytorch/train.py`\n",
        "\n",
        "```py\n",
        "augpipe_specs = {\n",
        "    'blit':   dict(xflip=1, rotate90=1, xint=1),\n",
        "    'bgcfnc': dict(xflip=1, rotate90=1, xint=1, scale=1, rotate=1, aniso=1, xfrac=1, brightness=1, contrast=1, lumaflip=1, hue=1, saturation=1, imgfilter=1, noise=1, cutout=1),\n",
        "}\n",
        "```\n",
        "\n",
        "```sh\n",
        "default: bgc\n",
        "\n",
        "bilt : x-flip 하나만 적용하고 싶다.\n",
        "geom : 모두 적용하는데, rotation 계수만 조절하고 싶다.\n",
        "color : 모두 적용하는데, 계수는 어느정도 조절하고 싶긴 하다.\n",
        "filter : 모두 적용\n",
        "noise : 적용\n",
        "cutout : 적용\n",
        "\n",
        "augpipe_specs -> augment_kwargs\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NurxuAcviCkJ"
      },
      "outputs": [],
      "source": [
        "# augpipe에서 0.7 같은 값도 받는지 테스트\n",
        "\n",
        "# .json 파일 추가 후 cond=1 옵션 주기\n",
        "\n",
        "# --resume"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AXl-a54ciCkJ",
        "outputId": "2918e364-2da6-4ad7-cddf-a45f9343452c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training options:\n",
            "{\n",
            "  \"num_gpus\": 1,\n",
            "  \"image_snapshot_ticks\": 100,\n",
            "  \"network_snapshot_ticks\": 100,\n",
            "  \"metrics\": [\n",
            "    \"fid50k_full\"\n",
            "  ],\n",
            "  \"random_seed\": 0,\n",
            "  \"training_set_kwargs\": {\n",
            "    \"class_name\": \"training.dataset.ImageFolderDataset\",\n",
            "    \"path\": \"pokemon-generator/dataset/images\",\n",
            "    \"use_labels\": false,\n",
            "    \"max_size\": 1195,\n",
            "    \"xflip\": true,\n",
            "    \"resolution\": 390\n",
            "  },\n",
            "  \"data_loader_kwargs\": {\n",
            "    \"pin_memory\": true,\n",
            "    \"num_workers\": 3,\n",
            "    \"prefetch_factor\": 2\n",
            "  },\n",
            "  \"G_kwargs\": {\n",
            "    \"class_name\": \"training.networks.Generator\",\n",
            "    \"z_dim\": 512,\n",
            "    \"w_dim\": 512,\n",
            "    \"mapping_kwargs\": {\n",
            "      \"num_layers\": 2\n",
            "    },\n",
            "    \"synthesis_kwargs\": {\n",
            "      \"channel_base\": 16384,\n",
            "      \"channel_max\": 512,\n",
            "      \"num_fp16_res\": 4,\n",
            "      \"conv_clamp\": 256\n",
            "    }\n",
            "  },\n",
            "  \"D_kwargs\": {\n",
            "    \"class_name\": \"training.networks.Discriminator\",\n",
            "    \"block_kwargs\": {},\n",
            "    \"mapping_kwargs\": {},\n",
            "    \"epilogue_kwargs\": {\n",
            "      \"mbstd_group_size\": 4\n",
            "    },\n",
            "    \"channel_base\": 16384,\n",
            "    \"channel_max\": 512,\n",
            "    \"num_fp16_res\": 4,\n",
            "    \"conv_clamp\": 256\n",
            "  },\n",
            "  \"G_opt_kwargs\": {\n",
            "    \"class_name\": \"torch.optim.Adam\",\n",
            "    \"lr\": 0.0025,\n",
            "    \"betas\": [\n",
            "      0,\n",
            "      0.99\n",
            "    ],\n",
            "    \"eps\": 1e-08\n",
            "  },\n",
            "  \"D_opt_kwargs\": {\n",
            "    \"class_name\": \"torch.optim.Adam\",\n",
            "    \"lr\": 0.0025,\n",
            "    \"betas\": [\n",
            "      0,\n",
            "      0.99\n",
            "    ],\n",
            "    \"eps\": 1e-08\n",
            "  },\n",
            "  \"loss_kwargs\": {\n",
            "    \"class_name\": \"training.loss.StyleGAN2Loss\",\n",
            "    \"r1_gamma\": 3.0420000000000003\n",
            "  },\n",
            "  \"total_kimg\": 25000,\n",
            "  \"batch_size\": 4,\n",
            "  \"batch_gpu\": 4,\n",
            "  \"ema_kimg\": 3.125,\n",
            "  \"ema_rampup\": 0.05,\n",
            "  \"ada_target\": 0.6,\n",
            "  \"augment_kwargs\": {\n",
            "    \"class_name\": \"training.augment.AugmentPipe\",\n",
            "    \"xflip\": 1,\n",
            "    \"rotate90\": 1,\n",
            "    \"xint\": 0.7\n",
            "  },\n",
            "  \"run_dir\": \"./training-runs/00002-images-mirror-auto1-batch4-blit\"\n",
            "}\n",
            "\n",
            "Output directory:   ./training-runs/00002-images-mirror-auto1-batch4-blit\n",
            "Training data:      pokemon-generator/dataset/images\n",
            "Training duration:  25000 kimg\n",
            "Number of GPUs:     1\n",
            "Number of images:   1195\n",
            "Image resolution:   390\n",
            "Conditional model:  False\n",
            "Dataset x-flips:    True\n",
            "\n",
            "Creating output directory...\n",
            "Launching processes...\n",
            "Loading training set...\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/sampler.py:64: UserWarning: `data_source` argument is not used and will be removed in 2.2.0.You may still have custom implementation that utilizes it.\n",
            "  warnings.warn(\"`data_source` argument is not used and will be removed in 2.2.0.\"\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 3 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "\n",
            "Num images:  2390\n",
            "Image shape: [3, 390, 390]\n",
            "Label shape: [0]\n",
            "\n",
            "Constructing networks...\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/stylegan2-ada-pytorch/train.py\", line 538, in <module>\n",
            "    main() # pylint: disable=no-value-for-parameter\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/click/core.py\", line 1157, in __call__\n",
            "    return self.main(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/click/core.py\", line 1078, in main\n",
            "    rv = self.invoke(ctx)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/click/core.py\", line 1434, in invoke\n",
            "    return ctx.invoke(self.callback, **ctx.params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/click/core.py\", line 783, in invoke\n",
            "    return __callback(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/click/decorators.py\", line 33, in new_func\n",
            "    return f(get_current_context(), *args, **kwargs)\n",
            "  File \"/content/stylegan2-ada-pytorch/train.py\", line 531, in main\n",
            "    subprocess_fn(rank=0, args=args, temp_dir=temp_dir)\n",
            "  File \"/content/stylegan2-ada-pytorch/train.py\", line 383, in subprocess_fn\n",
            "    training_loop.training_loop(rank=rank, **args)\n",
            "  File \"/content/stylegan2-ada-pytorch/training/training_loop.py\", line 150, in training_loop\n",
            "    G = dnnlib.util.construct_class_by_name(**G_kwargs, **common_kwargs).train().requires_grad_(False).to(device) # subclass of torch.nn.Module\n",
            "  File \"/content/stylegan2-ada-pytorch/dnnlib/util.py\", line 289, in construct_class_by_name\n",
            "    return call_func_by_name(*args, func_name=class_name, **kwargs)\n",
            "  File \"/content/stylegan2-ada-pytorch/dnnlib/util.py\", line 284, in call_func_by_name\n",
            "    return func_obj(*args, **kwargs)\n",
            "  File \"/content/stylegan2-ada-pytorch/torch_utils/persistence.py\", line 104, in __init__\n",
            "    super().__init__(*args, **kwargs)\n",
            "  File \"/content/stylegan2-ada-pytorch/training/networks.py\", line 493, in __init__\n",
            "    self.synthesis = SynthesisNetwork(w_dim=w_dim, img_resolution=img_resolution, img_channels=img_channels, **synthesis_kwargs)\n",
            "  File \"/content/stylegan2-ada-pytorch/torch_utils/persistence.py\", line 104, in __init__\n",
            "    super().__init__(*args, **kwargs)\n",
            "  File \"/content/stylegan2-ada-pytorch/training/networks.py\", line 434, in __init__\n",
            "    assert img_resolution >= 4 and img_resolution & (img_resolution - 1) == 0\n",
            "AssertionError\n",
            "Exception ignored in atexit callback: <function _exit_function at 0x7d4e2ee5d750>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/multiprocessing/util.py\", line 357, in _exit_function\n",
            "    p.join()\n",
            "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 149, in join\n",
            "    res = self._popen.wait(timeout)\n",
            "  File \"/usr/lib/python3.10/multiprocessing/popen_fork.py\", line 43, in wait\n",
            "    return self.poll(os.WNOHANG if timeout == 0.0 else 0)\n",
            "  File \"/usr/lib/python3.10/multiprocessing/popen_fork.py\", line 27, in poll\n",
            "    pid, sts = os.waitpid(self.pid, flag)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/signal_handling.py\", line 66, in handler\n",
            "    _error_if_any_worker_fails()\n",
            "RuntimeError: DataLoader worker (pid 7008) is killed by signal: Terminated. \n"
          ]
        }
      ],
      "source": [
        "# 테스트\n",
        "!python stylegan2-ada-pytorch/train.py \\\n",
        "    --data=pokemon-generator/dataset/images \\\n",
        "    --mirror=true \\\n",
        "    --augpipe=blit \\\n",
        "    --outdir=./training-runs \\\n",
        "    --snap=100 \\\n",
        "    --gpus=1 \\\n",
        "    --batch 4\n",
        "#    --dry-run"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eXT7rqKIiCkJ"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}